{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(98052)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(98052)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORIES = ['waterways', 'fieldborders', 'terraces', 'wsb']\n",
    "CLASS_DICT = {1: 'waterways', 2: 'fieldborders', 3: 'terraces', 4: 'wsb'}\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "IMAGE_H = 256\n",
    "IMAGE_W = 256\n",
    "\n",
    "JPG_NAME = 'jpg'\n",
    "\n",
    "logs = 'coco20180328T0043'# lr = 0.0001\n",
    "\n",
    "val_dir = '/data/a/LOLRaw/data/processed_large/fourclasses/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[64 64]\n",
      " [32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    5\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LOLConfig(Config):\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    # GPU_COUNT = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + NUM_CLASSES  # COCO has 80 classes\n",
    "    \n",
    "config = LOLConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_mask_path(mask_dir, filename):\n",
    "    fn_img, ext = os.path.splitext(os.path.basename(filename))\n",
    "    mask_endings = [x for x in CATEGORIES if x != fn_img.split('_')[0]]\n",
    "    mask_path = [os.path.join(mask_dir, filename)]\n",
    "    for ending in mask_endings:\n",
    "        mask_path.append( os.path.join(mask_dir, fn_img + '_'+ ending + '.jpg'))\n",
    "    return mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersec = y_true*y_pred\n",
    "    union = np.logical_or(y_true, y_pred).astype(int)\n",
    "    if intersec.sum() == 0:\n",
    "        jac_coef = 0\n",
    "    else:\n",
    "        jac_coef = intersec.sum()/union.sum()\n",
    "    return jac_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot predict masks over the true values\n",
    "import colorsys\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def display_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None):\n",
    "    \n",
    "    # Number of instances\n",
    "    N = masks.shape[2]\n",
    "\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "        print (color)\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        masked_image = apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "            ax.add_patch(p)\n",
    "    ax.imshow(masked_image.astype(np.uint8))\n",
    "    plt.show()\n",
    "    return masked_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LolDataset(utils.Dataset):\n",
    "    \n",
    "    def load_LOL(self, datasetdir):\n",
    "        \n",
    "        for i in range(NUM_CLASSES):\n",
    "            self.add_class(\"shapes\", i, CLASS_DICT[i+1] )\n",
    "        \n",
    "        image_dir = os.path.join(datasetdir, JPG_NAME)\n",
    "        mask_dir = os.path.join(datasetdir, 'polygon')\n",
    "        \n",
    "        image_names = next(os.walk(image_dir))[2]\n",
    "        for i in range(len(image_names)):\n",
    "            self.add_image(\"shapes\", image_id = i,\n",
    "                    path=os.path.join(image_dir, image_names[i]),\n",
    "                    mask_path = generate_mask_path(mask_dir, image_names[i]),\n",
    "                    width=IMAGE_W,\n",
    "                    height=IMAGE_H)\n",
    "        \n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        image_path = info['path']\n",
    "        image_BGR = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        mask_path = info['mask_path']\n",
    "        valid_mask = []\n",
    "        for _mask_path in mask_path:\n",
    "            _mask = cv2.imread(_mask_path, 0)\n",
    "            \n",
    "            if _mask.max() == _mask.min():\n",
    "                pass\n",
    "            else:\n",
    "                valid_mask.append(_mask_path)\n",
    "             \n",
    "        count = len(valid_mask)\n",
    "        mask = np.zeros([info['height'], info['width'], count], 'uint8')\n",
    "        shapes = []\n",
    "        for i in range(count):\n",
    "            img_array = cv2.imread(valid_mask[i], 0)\n",
    "            (thresh, im_bw) = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "            mask_array = (img_array < thresh).astype('uint8')\n",
    "            mask[:, :, i:i+1] = np.expand_dims(mask_array, axis=2)\n",
    "            fn_img, ext = os.path.splitext(valid_mask[i])\n",
    "\n",
    "            if fn_img.split('_')[-1] == 'merged':\n",
    "                shapes.append(fn_img.split('/')[-1].split('_')[0])\n",
    "            else:\n",
    "                shapes.append(fn_img.split('_')[-1])\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s) for s in shapes])\n",
    "        \n",
    "        return mask, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = LolDataset()\n",
    "dataset_val.load_LOL(val_dir)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(LOLConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDtoName(image_id):\n",
    "    for i in range(len(dataset_val.image_info)):\n",
    "        if image_id == dataset_val.image_info[i]['id']:\n",
    "            image_name = dataset_val.image_info[i]['path'].split('/')[-1]\n",
    "    return image_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NametoID(image_name):\n",
    "    for i in range(len(dataset_val.image_info)):\n",
    "        if image_name == dataset_val.image_info[i]['path'].split('/')[-1]:\n",
    "            image_id = dataset_val.image_info[i]['id']\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /home/tinzha/Projects/LandOLakes/logs/coco20180328T0043/mask_rcnn_coco_0100.h5\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/tinzha/Projects/LandOLakes/logs/' + logs + '/mask_rcnn_coco_'+\"{0:0=4d}\".format(epoch)+'.h5'\n",
    "\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
